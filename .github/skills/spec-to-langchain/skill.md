---
name: spec-to-langchain
description: Generate LangGraph skeleton code from Flow Spec YAML files.
---

# Spec to LangChain Skill

## What This Skill Does

**Agent ç›´æ¥é–±è®€** `specs/*.yaml` Flow Spec æª”æ¡ˆï¼Œ**æ‰‹å·¥æ’°å¯«**å®Œæ•´çš„ LangGraph ç¨‹å¼ç¢¼ï¼ŒåŒ…å«ï¼š
- `graph.py` - LangGraph ä¸»é‚è¼¯ï¼ˆStateã€Nodesã€Graphï¼‰
- `run.py` - æ¸¬è©¦åŸ·è¡Œå…¥å£
- `__init__.py` - æ¨¡çµ„åŒ¯å‡º

âš ï¸ **é‡è¦ï¼š** é€™å€‹ Skill è¦æ±‚ Agent æ ¹æ“š Spec **ç›´æ¥ç”Ÿæˆç¨‹å¼ç¢¼**ï¼Œè€ŒéåŸ·è¡Œè…³æœ¬ç”¢ç”Ÿã€‚

## Strategic Purposeï¼ˆæˆ°ç•¥ç›®çš„ï¼‰

é€™å€‹æ­¥é©Ÿæ˜¯ã€Œ**Copilot å¯¦é©—å®¤ â†’ Databricks ç”Ÿç”¢ç’°å¢ƒ**ã€è½‰åŒ–æµç¨‹ä¸­çš„é—œéµæ©‹æ¨‘ï¼š

```
Agent éš¨æ©Ÿè¡Œç‚º (Copilot Trace)
    â†“ çµæ§‹åŒ–
Flow Spec (æ¨™æº–ä½œæ¥­ç¨‹åº)
    â†“ ç¨‹å¼åŒ–ï¼ˆæ­¤ Skillï¼‰
LangGraph Code (å¯æ¸¬è©¦ã€å¯é©—è­‰çš„æµç¨‹)
    â†“ ä¼æ¥­åŒ–
Databricks Mosaic AI (UC Functions + Workflows)
```

### ç‚ºä»€éº¼éœ€è¦ LangGraph é€™ä¸€å±¤ï¼Ÿ

1. **é©—è­‰é‚è¼¯æ­£ç¢ºæ€§** - åœ¨ç§»æ¤åˆ° Databricks å‰å…ˆæœ¬åœ°æ¸¬è©¦
2. **è­˜åˆ¥å¯é‡ç”¨å…ƒä»¶** - Node functions â†’ UC Functions çš„å€™é¸æ¸…å–®
3. **å®šç¾©ç‹€æ…‹æµè½‰** - FlowState â†’ Databricks Job Parameters çš„è¨­è¨ˆåŸºç¤
4. **æ•æ‰éŒ¯èª¤è™•ç†** - recovery_playbook â†’ ä¼æ¥­ç´š SLA çš„éœ€æ±‚ä¾†æº

## When to Use

ç•¶ä½ å·²ç¶“æœ‰ Flow Specï¼ˆé€é `trace-to-flow` skill ç”¢ç”Ÿï¼‰ä¸¦æƒ³è¦ç”Ÿæˆå°æ‡‰çš„ LangChain/LangGraph ç¨‹å¼ç¢¼æ™‚ã€‚

## How Agent Should Work

### Step 1: åˆ—å‡ºä¸¦é¸æ“‡ Spec

Agent æ‡‰è©²åˆ—å‡º `specs/` ç›®éŒ„ä¸­çš„æ‰€æœ‰ `.flow_spec.yaml` æª”æ¡ˆï¼Œä¸¦è®“ä½¿ç”¨è€…é¸æ“‡æˆ–è‡ªå‹•åŒ¹é…ã€‚

### Step 2: è®€å–ä¸¦ç†è§£ Spec

```python
# Agent è®€å– specs/<name>.flow_spec.yaml
import yaml
with open(f'specs/{spec_name}.flow_spec.yaml') as f:
    spec = yaml.safe_load(f)
```

### Step 3: ç”Ÿæˆç¨‹å¼ç¢¼æª”æ¡ˆ

Agent æ‡‰è©²ç›´æ¥ä½¿ç”¨ `create_file` å·¥å…·å‰µå»ºä»¥ä¸‹ä¸‰å€‹æª”æ¡ˆï¼š

1. `flows/<flow_name>/__init__.py`
2. `flows/<flow_name>/graph.py`
3. `flows/<flow_name>/run.py`

## Code Generation Rules

### 1. File: `__init__.py`

ç°¡å–®çš„æ¨¡çµ„åŒ¯å‡ºï¼š

```python
from .graph import graph, build_graph

__all__ = ["graph", "build_graph"]
```

### 2. File: `graph.py`

**çµæ§‹è¦æ±‚ï¼š**

```python
"""
<Flow Name> - LangGraph Implementation

åŸºæ–¼ specs/<spec-name>.flow_spec.yaml ç”Ÿæˆçš„ LangGraph æµç¨‹
ç›®æ¨™ï¼š<goal from spec>

Phases:
<list all phases with steps>
"""

import sys
from pathlib import Path
from typing import TypedDict

from langgraph.graph import StateGraph, START, END

# å¦‚æœéœ€è¦ä½¿ç”¨å…¶ä»– skillsï¼ŒåŠ å…¥åˆ° path
PROJECT_ROOT = Path(__file__).parent.parent.parent
# sys.path.insert(0, str(PROJECT_ROOT / ".github" / "skills" / "<skill-name>" / "scripts"))

# =============================================================================
# State Definition
# =============================================================================

class FlowState(TypedDict):
    """Flow ç‹€æ…‹"""
    task: str                          # è¼¸å…¥ï¼šä»»å‹™æè¿°
    # æ ¹æ“š spec.phases[].outputs ç”Ÿæˆç‹€æ…‹æ¬„ä½
    # æ ¹æ“šéœ€è¦åŠ å…¥ä¸­é–“çµæœæ¬„ä½
    error: str | None                  # éŒ¯èª¤è¨Šæ¯ï¼ˆå¦‚æœ‰ï¼‰


# =============================================================================
# Node Functions
# =============================================================================

def <phase_name_lower>_node(state: FlowState) -> dict:
    """
    Phase: <PhaseName> - <phase description>
    
    Steps:
    <list phase steps>
    
    Tools: <list tools if any>
    Dependencies: <list dependencies if any>
    """
    # å¯¦ä½œé‚è¼¯ï¼š
    # 1. å¾ state ä¸­å–å¾—å¿…è¦è³‡è¨Š
    # 2. åŸ·è¡Œè©² phase çš„æ ¸å¿ƒé‚è¼¯
    # 3. è™•ç† failure_modesï¼ˆå¦‚æœ spec æœ‰è¨˜éŒ„ï¼‰
    # 4. å›å‚³æ›´æ–°çš„ç‹€æ…‹
    
    print(f"[{<PhaseName>}] <æè¿°å‹•ä½œ>")
    
    # TODO: å¯¦ä½œè©² phase çš„é‚è¼¯
    
    return {<updated_fields>}


# ç‚ºæ¯å€‹ phase ç”Ÿæˆä¸€å€‹ node function


# =============================================================================
# Graph Construction
# =============================================================================

def build_graph() -> StateGraph:
    """æ§‹å»º LangGraph æµç¨‹åœ–"""
    graph = StateGraph(FlowState)
    
    # åŠ å…¥æ‰€æœ‰ phase nodes
    graph.add_node("<phase1>", <phase1>_node)
    graph.add_node("<phase2>", <phase2>_node)
    # ... ç‚ºæ¯å€‹ phase åŠ å…¥ node
    
    # ç·šæ€§é€£æ¥ï¼ˆå¯æ ¹æ“šå¯¦éš›éœ€æ±‚èª¿æ•´ï¼‰
    graph.add_edge(START, "<phase1>")
    graph.add_edge("<phase1>", "<phase2>")
    # ...
    graph.add_edge("<last_phase>", END)
    
    return graph.compile()


# å»ºç«‹å¯åŒ¯å‡ºçš„ graph instance
graph = build_graph()
```

**é—œéµè¨­è¨ˆåŸå‰‡ï¼š**

- **FlowState æ¬„ä½å‘½åï¼š** æ ¹æ“š `spec.phases[].outputs` ä¸­çš„æª”æ¡ˆåè½‰æ›ï¼ˆå¦‚ `data_fetch_profile.json` â†’ `profile: dict | None`ï¼‰
- **Node Function å‘½åï¼š** `<phase.name.lower()>_node`ï¼ˆå¦‚ `Fetch` â†’ `fetch_node`ï¼‰
- **å¯¦ä½œåƒè€ƒ traceï¼š** å¦‚æœ spec æœ‰ `recovery_playbook`ï¼Œæ‡‰åœ¨ node ä¸­å¯¦ä½œéŒ¯èª¤è™•ç†
- **Skills æ•´åˆï¼š** æª¢æŸ¥æ˜¯å¦æœ‰å·²å­˜åœ¨çš„ skills å¯é‡ç”¨ï¼ˆå¦‚ `data-fetch`ï¼‰

**ğŸ’¡ Databricks ç§»æ¤æç¤ºï¼ˆåœ¨ç¨‹å¼ç¢¼è¨»è§£ä¸­æ¨™è¨»ï¼‰ï¼š**

åœ¨ç”Ÿæˆçš„ `graph.py` ä¸­ï¼Œå°æ–¼æ¯å€‹ node functionï¼ŒAgent æ‡‰è©²åŠ å…¥è¨»è§£æ¨™è¨»ï¼š

```python
def fetch_node(state: FlowState) -> dict:
    """
    Phase: Fetch - åŸ·è¡Œ data-fetch æ’ˆå–æ•¸æ“š
    
    # ğŸ¢ Databricks Migration Notes:
    # - æ­¤ node å¯å°è£ç‚º UC Function: `uc.data.fetch_profile(dataset_key: str) -> dict`
    # - Dependencies: pandas, yaml â†’ éœ€åœ¨ UC Function ç’°å¢ƒä¸­é è£
    # - Data Source: å°‡å¾ Delta Tables è®€å–è€Œé CSV
    # - Trace: ä½¿ç”¨ MLflow logging å–ä»£ print statements
    """
    # ... implementation
```

é€™äº›è¨»è§£å°‡ä½œç‚ºæœªä¾† Databricks éƒ¨ç½²æ™‚çš„é‡è¦åƒè€ƒã€‚

### 3. File: `run.py`

æ¸¬è©¦å…¥å£ç¨‹å¼ï¼š

```python
#!/usr/bin/env python3
"""
<Flow Name> - Test Runner
"""

import argparse
from graph import graph

def main():
    parser = argparse.ArgumentParser(description='Run <flow_name> flow')
    parser.add_argument('--task', type=str, required=True, help='ä»»å‹™æè¿°')
    parser.add_argument('--verbose', action='store_true', help='é¡¯ç¤ºè©³ç´°è¼¸å‡º')
    args = parser.parse_args()
    
    # æº–å‚™åˆå§‹ç‹€æ…‹
    initial_state = {
        "task": args.task,
        # æ ¹æ“š FlowState åˆå§‹åŒ–å…¶ä»–æ¬„ä½ç‚º None
    }
    
    print(f"\n{'='*60}")
    print(f"åŸ·è¡Œ <Flow Name>")
    print(f"ä»»å‹™: {args.task}")
    print(f"{'='*60}\n")
    
    # åŸ·è¡Œ graph
    result = graph.invoke(initial_state)
    
    print(f"\n{'='*60}")
    print("åŸ·è¡Œçµæœï¼š")
    print(f"{'='*60}")
    
    if args.verbose:
        for key, value in result.items():
            print(f"{key}: {value}")
    else:
        # åªé¡¯ç¤ºé‡è¦æ¬„ä½
        if result.get("error"):
            print(f"âŒ éŒ¯èª¤: {result['error']}")
        else:
            print("âœ… åŸ·è¡ŒæˆåŠŸ")
            # æ ¹æ“š flow ç‰¹æ€§é¡¯ç¤ºé—œéµçµæœ

if __name__ == "__main__":
    main()
```

## Agent Execution Example

ç•¶ä½¿ç”¨è€…èªªï¼š`/spec-to-langchain take-data-test`

Agent æ‡‰è©²ï¼š

1. **åˆ—å‡º specs**ï¼šä½¿ç”¨ `list_dir` æŸ¥çœ‹ `specs/` ç›®éŒ„
2. **åŒ¹é…åç¨±**ï¼šæ‰¾åˆ° `specs/take-data-test.flow_spec.yaml`
3. **è®€å– spec**ï¼šä½¿ç”¨ `read_file` è®€å–å®Œæ•´ YAML
4. **åˆ†æçµæ§‹**ï¼š
   - `run_name`: take-data-test
   - `goal`ï¼ˆå®Œæ•´æµç¨‹ï¼‰

```
1. Agent åŸ·è¡Œä»»å‹™ (Copilot Sandbox)
   â†’ runs/<timestamp>-<name>/trace.ndjson
   
2. trace-to-flow (çµæ§‹åŒ–)
   â†’ specs/<name>.flow_spec.yaml
   
3. spec-to-langchain (ç¨‹å¼åŒ–) â† ç•¶å‰ Skill
   â†’ flows/<name>/{__init__.py, graph.py, run.py}
   
4. æœ¬åœ°æ¸¬è©¦èˆ‡é©—è­‰
   â†’ python flows/<name>/run.py --task "..."
   â†’ ç¢ºèªé‚è¼¯æ­£ç¢ºæ€§ã€è­˜åˆ¥å¯é‡ç”¨å…ƒä»¶
   
5. [Future] Databricks ç§»æ¤
   â†’ Node Functions â†’ UC Functions
   â†’ FlowState â†’ Job Parameters
   â†’ Error Handling â†’ Workflow Retry Logic
   â†’ Local Data â†’ Delta Tables
```

## Databricks Migration Mappingï¼ˆç§»æ¤å°ç…§ï¼‰

ç•¶ç”Ÿæˆ LangGraph ç¨‹å¼ç¢¼æ™‚ï¼ŒAgent æ‡‰è©²æ€è€ƒä»¥ä¸‹å°æ‡‰é—œä¿‚ï¼š

| LangGraph Component | Databricks Component | Migration Action |
|---------------------|---------------------|------------------|
| `FlowState` (TypedDict) | Job Parameters / Delta Table Schema | å®šç¾©æ•¸æ“šæµè½‰çµæ§‹ |
| `<phase>_node()` | UC Function | å°è£ç‚ºå¯æ²»ç†çš„å·¥å…· |
| `skills/` imports | UC Functions Library | æ¨™æº–åŒ–å·¥å…·é›† |
| `print()` logging | MLflow Logging | ä¼æ¥­ç´šè¿½è¹¤ |
| Local CSV | Delta Tables | ç”Ÿç”¢æ•¸æ“šæº |
| `graph.compile()` | Databricks Workflows | ç·¨æ’é‚è¼¯ |
| Error handling | Retry Policies + Alerts | SLA ä¿è­‰ |

## Dependencies

Flow ç¨‹å¼ç¢¼éœ€è¦ï¼š
- Python 3.10+
- LangGraph (`pip install langgraph`)
- å…¶ä»–ä¾è³´è¦– spec ä¸­çš„ `dependencies` è€Œå®š

**ğŸ” ç§»æ¤æª¢æŸ¥æ¸…å–®ï¼š**
- [ ] æ‰€æœ‰ dependencies æ˜¯å¦åœ¨ Databricks Runtime ä¸­å¯ç”¨ï¼Ÿ
- [ ] æ˜¯å¦æœ‰ä½¿ç”¨æœ¬åœ°æª”æ¡ˆè·¯å¾‘ï¼Ÿï¼ˆéœ€æ”¹ç‚º DBFS/Unity Catalogï¼‰
- [ ] æ˜¯å¦æœ‰ print() éœ€æ”¹ç‚º MLflow loggingï¼Ÿ
- [ ] å“ªäº› node functions å¯ä»¥å…±ç”¨ï¼Ÿï¼ˆæŠ½å–ç‚º UC Functionsï¼‰
- å¯¦ä½œéŒ¯èª¤è™•ç†
- å®šç¾©æ¸…æ™°çš„ State çµæ§‹
- ä¸²æ¥å¤šå€‹ phases

## Workflow

```
1. Agent åŸ·è¡Œä»»å‹™ â†’ runs/<timestamp>-<name>/trace.ndjson
2. trace-to-flow   â†’ specs/<name>.flow_spec.yaml
3. Agent è®€å– spec â†’ ç›´æ¥ç”Ÿæˆ flows/<name>/{__init__.py, graph.py, run.py}
4. æ¸¬è©¦ï¼špython flows/<name>/run.py --task "..."
5. å®Œå–„ï¼šæ ¹æ“šæ¸¬è©¦çµæœèª¿æ•´ç¨‹å¼ç¢¼
```

## Dependencies

Flow ç¨‹å¼ç¢¼éœ€è¦ï¼š
- Python 3.10+
- LangGraph (`pip install langgraph`)
- å…¶ä»–ä¾è³´è¦– spec ä¸­çš„ `dependencies` è€Œå®š
