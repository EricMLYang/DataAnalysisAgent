"""æœ€ç°¡å–®çš„ LangChain å·¥å…·é¸æ“‡ç¯„ä¾‹ - æ•´åˆ Skill Loader"""
import sys
from pathlib import Path

# åŠ å…¥å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python path
root_dir = Path(__file__).parent.parent.parent
sys.path.insert(0, str(root_dir))

from langchain_core.tools import tool
from langchain_openai import AzureChatOpenAI
import yaml
from skill_loader import load_skills_simple

# è¼‰å…¥è¨­å®š
with open(root_dir / "config" / "secret.yml") as f:
    config = yaml.safe_load(f)

# å®šç¾©ç°¡å–®å·¥å…·
@tool
def calculator(expression: str) -> str:
    """ç”¨æ–¼è¨ˆç®—æ•¸å­¸è¡¨é”å¼ï¼Œä¾‹å¦‚ï¼š2+2, 10*5"""
    try:
        result = eval(expression)
        return f"è¨ˆç®—çµæœ: {result}"
    except:
        return "è¨ˆç®—éŒ¯èª¤"

@tool
def get_weather(city: str) -> str:
    """æŸ¥è©¢æŒ‡å®šåŸå¸‚çš„å¤©æ°£"""
    return f"{city}çš„å¤©æ°£æ˜¯æ™´å¤©ï¼Œæº«åº¦25åº¦"

@tool
def search_web(query: str) -> str:
    """åœ¨ç¶²è·¯ä¸Šæœå°‹è³‡è¨Š"""
    return f"æœå°‹ '{query}' çš„çµæœ..."

# è¨­å®š LLM
llm = AzureChatOpenAI(
    azure_endpoint=config["API_BASE"],
    api_key=config["API_KEY"],
    api_version=config["API_VERSION"],
    deployment_name=config["DEPLOYMENT_NAME"],
    temperature=0
)

print("\nğŸ”„ è¼‰å…¥æŠ€èƒ½ä¸­...")
print("-" * 60)

# è¼‰å…¥æ‰‹å‹•å®šç¾©çš„å·¥å…·
manual_tools = [calculator, get_weather, search_web]

# è‡ªå‹•è¼‰å…¥ skillsï¼ˆç›®å‰åªè¼‰å…¥ data-fetchï¼‰
skill_tools = load_skills_simple(['data-fetch'])

# åˆä½µæ‰€æœ‰å·¥å…·
all_tools = manual_tools + skill_tools

print(f"âœ… ç¸½å…±è¼‰å…¥ {len(all_tools)} å€‹å·¥å…·")
print("-" * 60)

# ç¶å®šå·¥å…·
llm_with_tools = llm.bind_tools(all_tools)

print("\n" + "=" * 60)
print("ğŸ¤– LangChain å·¥å…·é¸æ“‡æ¸¬è©¦ - äº’å‹•æ¨¡å¼ï¼ˆå« Skillsï¼‰")
print("=" * 60)
print("å¯ç”¨å·¥å…·:")
print("  ğŸ“Š calculator - è¨ˆç®—æ•¸å­¸è¡¨é”å¼")
print("  ğŸŒ¤ï¸  get_weather - æŸ¥è©¢åŸå¸‚å¤©æ°£")
print("  ğŸ” search_web - ç¶²è·¯æœå°‹")
for tool in skill_tools:
    print(f"  ğŸ”§ {tool.name} - {tool.description[:50]}...")
print("\nè¼¸å…¥ 'exit' æˆ– 'quit' çµæŸç¨‹å¼\n")

# äº’å‹•è¿´åœˆ
while True:
    question = input("ğŸ‘¤ è«‹è¼¸å…¥å•é¡Œ: ").strip()
    
    if question.lower() in ['exit', 'quit', '']:
        print("ğŸ‘‹ å†è¦‹ï¼")
        break
    
    print("-" * 60)
    
    # èª¿ç”¨ LLM
    response = llm_with_tools.invoke(question)
    
    # æª¢æŸ¥æ˜¯å¦é¸æ“‡äº†å·¥å…·
    if response.tool_calls:
        for tool_call in response.tool_calls:
            print(f"âœ… é¸æ“‡çš„å·¥å…·: {tool_call['name']}")
            print(f"   åƒæ•¸: {tool_call['args']}")
    else:
        print("âŒ æ²’æœ‰é¸æ“‡å·¥å…·")
        print(f"   å›ç­”: {response.content}")
    
    print()
